# üöÄ AI Resume Intelligence & Career Copilot

<div align="center">

**A full-stack web application that analyzes resumes against job descriptions using explainable AI techniques**

[![Python](https://img.shields.io/badge/Python-3.11+-blue.svg)](https://www.python.org/)
[![FastAPI](https://img.shields.io/badge/FastAPI-0.109-green.svg)](https://fastapi.tiangolo.com/)
[![React](https://img.shields.io/badge/React-18-blue.svg)](https://reactjs.org/)
[![TypeScript](https://img.shields.io/badge/TypeScript-5.2-blue.svg)](https://www.typescriptlang.org/)
[![PostgreSQL](https://img.shields.io/badge/PostgreSQL-14+-blue.svg)](https://www.postgresql.org/)

[Features](#-key-features) ‚Ä¢ [Tech Stack](#-technology-stack) ‚Ä¢ [Quick Start](#-quick-start) ‚Ä¢ [Architecture](#-system-architecture) ‚Ä¢ [Demo](#-demo)

</div>

---

## üìã Table of Contents

- [Overview](#-overview)
- [Key Features](#-key-features)
- [Technology Stack](#-technology-stack)
- [Quick Start](#-quick-start)
- [System Architecture](#-system-architecture)
- [Key Highlights](#-key-highlights)
- [Technical Deep Dive](#-technical-deep-dive)
- [API Documentation](#-api-documentation)
- [Project Structure](#-project-structure)
- [Testing](#-testing)
- [Future Enhancements](#-future-enhancements)

---

## üéØ Overview

**AI Resume Intelligence & Career Copilot** is a production-ready full-stack application that helps job seekers understand their fit for positions by providing transparent, explainable resume-to-job-description matching analysis.

### The Problem

Job seekers face a frustrating cycle: they apply to positions but receive no feedback on why they were rejected. Traditional ATS (Applicant Tracking Systems) operate as black boxes, leaving candidates guessing about skill mismatches and missing requirements.

### The Solution

This application provides **explainable, transparent matching** using statistical and rule-based methods. Unlike black-box AI systems, every match score can be traced back to specific skills and keywords, giving users actionable insights to improve their applications.

### What Makes It Different

- ‚úÖ **Fully Explainable**: Uses TF-IDF and keyword matching (not neural networks)
- ‚úÖ **Transparent**: Shows exactly which skills matched and why
- ‚úÖ **Actionable**: Identifies missing skills with specific recommendations
- ‚úÖ **Interview-Ready**: All logic can be explained and justified
- ‚úÖ **Production-Quality**: Complete authentication, error handling, and testing

---

## ‚ú® Key Features

### üîê Authentication & Security
- JWT-based authentication with token expiration
- Secure password hashing using bcrypt
- User data isolation and access control
- Protected API endpoints

### üìÑ Resume Management
- PDF resume upload with drag-and-drop interface
- Automatic text extraction from PDF files
- Resume storage and organization
- Text content analysis and keyword extraction

### üíº Job Description Analysis
- Job description input and storage
- Requirement extraction and parsing
- Skill keyword identification
- Historical tracking of job descriptions

### üîç Explainable Matching Engine
- Resume-to-job-description comparison
- Match score calculation (0-100%)
- Detailed explanation of matches and gaps
- Missing skills identification with importance ranking
- Transparent scoring algorithm

### üìä Interactive Dashboard
- Analysis history tracking
- Match score trends over time (interactive charts)
- Most common missing skills analytics
- Summary statistics (total analyses, average score, best/worst)
- Clickable history for detailed review

### üé® User Experience
- Real-time feedback and loading states
- Dark/light mode support with system preference detection
- Responsive design for all devices (mobile-first)
- Accessible UI with keyboard navigation
- Toast notifications for user feedback
- Optimistic UI updates

---

## üõ† Technology Stack

### Backend
| Technology | Purpose | Version |
|------------|---------|---------|
| **Python** | Core language | 3.11+ |
| **FastAPI** | Async web framework | 0.109 |
| **SQLAlchemy** | ORM for database operations | 2.0 |
| **PostgreSQL** | Production database | 14+ |
| **Alembic** | Database migrations | 1.13 |
| **JWT (python-jose)** | Authentication tokens | 3.3 |
| **Bcrypt** | Password hashing | 4.0 |
| **scikit-learn** | TF-IDF vectorization | 1.4 |
| **PDFMiner** | PDF text extraction | Latest |
| **Pytest** | Testing framework | 7.4 |

### Frontend
| Technology | Purpose | Version |
|------------|---------|---------|
| **React** | UI framework | 18.2 |
| **TypeScript** | Type safety | 5.2 |
| **React Router** | Client-side routing | 6.20 |
| **Axios** | HTTP client | 1.6 |
| **Context API** | Global state management | Built-in |
| **Recharts** | Data visualization | 2.10 |
| **React Dropzone** | File uploads | 14.2 |
| **Vite** | Build tool & dev server | 5.0 |

### AI/ML
- **TF-IDF (Term Frequency-Inverse Document Frequency)**: Statistical keyword extraction
- **Custom keyword matching**: Rule-based exact and partial matching
- **Explainable algorithms**: No black-box models

---

## üöÄ Quick Start

### Prerequisites

- Python 3.11+
- Node.js 18+
- PostgreSQL 14+ (or SQLite for development)
- npm or yarn

### Backend Setup

```bash
# Navigate to backend directory
cd backend

# Create virtual environment
python -m venv venv
source venv/bin/activate  # On Windows: venv\Scripts\activate

# Install dependencies
pip install -r requirements.txt

# Set up environment variables
cp .env.example .env
# Edit .env with your database URL and secret key

# Run database migrations
alembic upgrade head

# Start development server
uvicorn app.main:app --reload
```

**Environment Variables** (`backend/.env`):
```env
DATABASE_URL=postgresql://user:password@localhost/dbname
SECRET_KEY=your-secret-key-here
ALGORITHM=HS256
ACCESS_TOKEN_EXPIRE_MINUTES=30
UPLOAD_DIR=./uploads
CORS_ORIGINS=["http://localhost:5173"]
```

### Frontend Setup

```bash
# Navigate to frontend directory
cd frontend

# Install dependencies
npm install

# Set up environment variables
cp .env.example .env
# Edit .env with your API URL

# Start development server
npm run dev
```

**Environment Variables** (`frontend/.env`):
```env
VITE_API_URL=http://localhost:8000
```

### Database Setup

**PostgreSQL:**
```sql
CREATE DATABASE ai_resume_intelligence;
CREATE USER ai_resume_user WITH PASSWORD 'your_password';
GRANT ALL PRIVILEGES ON DATABASE ai_resume_intelligence TO ai_resume_user;
```

**Run Migrations:**
```bash
cd backend
alembic upgrade head
```

### Running Tests

```bash
# Backend tests
cd backend
pytest

# With coverage report
pytest --cov=app --cov-report=html

# Frontend tests (if configured)
cd frontend
npm test
```

---

## üèó System Architecture

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê         ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê         ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ   React 18      ‚îÇ  HTTP   ‚îÇ   FastAPI       ‚îÇ  SQL    ‚îÇ   PostgreSQL    ‚îÇ
‚îÇ   Frontend      ‚îÇ‚óÑ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñ∫‚îÇ   Backend       ‚îÇ‚óÑ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñ∫‚îÇ   Database      ‚îÇ
‚îÇ   (TypeScript)  ‚îÇ         ‚îÇ   (Python 3.11)‚îÇ         ‚îÇ   (Production)  ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò         ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò         ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                                      ‚îÇ
                                      ‚îÇ
                            ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
                            ‚îÇ   Matching Engine ‚îÇ
                            ‚îÇ   (TF-IDF +       ‚îÇ
                            ‚îÇ   Keyword Logic)  ‚îÇ
                            ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

### Data Flow

1. **User uploads resume** ‚Üí PDF parsed ‚Üí Text extracted ‚Üí Stored in database
2. **User creates job description** ‚Üí Text analyzed ‚Üí Keywords extracted ‚Üí Stored
3. **User runs analysis** ‚Üí Matching engine compares resume vs job description
4. **Results calculated** ‚Üí Match score, matched skills, missing skills, explanation
5. **Results stored** ‚Üí Available in dashboard for historical tracking

### Architecture Principles

- **Separation of Concerns**: API layer, business logic, and data access are separated
- **Dependency Injection**: FastAPI's dependency system for testability
- **Stateless API**: JWT tokens enable horizontal scaling
- **Async Processing**: FastAPI handles concurrent requests efficiently
- **Type Safety**: TypeScript on frontend, Pydantic models on backend

---

## üåü Key Highlights

### Technical Achievements

‚úÖ **Full-Stack Development**: Built complete application from database to UI  
‚úÖ **Explainable AI**: Implemented transparent matching algorithm using TF-IDF  
‚úÖ **Security Best Practices**: JWT authentication, bcrypt hashing, user data isolation  
‚úÖ **Production-Ready**: Error handling, validation, testing, and documentation  
‚úÖ **Modern Tech Stack**: FastAPI, React 18, TypeScript, PostgreSQL  
‚úÖ **Clean Architecture**: Modular design with separation of concerns  
‚úÖ **User Experience**: Responsive design, accessibility, dark mode, real-time feedback  

### Skills Demonstrated

- **Backend**: FastAPI, SQLAlchemy, PostgreSQL, RESTful API design, authentication
- **Frontend**: React, TypeScript, Context API, responsive design, accessibility
- **AI/ML**: TF-IDF vectorization, keyword extraction, explainable algorithms
- **DevOps**: Database migrations, environment configuration, testing
- **Software Engineering**: Clean code, testing, documentation, error handling

---

## üî¨ Technical Deep Dive

### Explainable AI Approach

This system uses **statistical and rule-based methods** rather than neural networks. Every decision can be explained and traced back to the input text.

#### How It Works

**1. Text Preprocessing**
- Convert to lowercase
- Remove special characters
- Normalize whitespace
- Filter stop words

**2. Keyword Extraction (TF-IDF)**

**TF-IDF (Term Frequency-Inverse Document Frequency)** is a statistical method that scores words based on:
- **Term Frequency (TF)**: How often a word appears in the document
- **Inverse Document Frequency (IDF)**: How rare the word is across all documents

**Why TF-IDF?**
- Well-established information retrieval technique
- Transparent scoring (not a black box)
- Can be explained in interviews
- Provides importance-weighted keywords

**3. Keyword Matching**

- **Exact Matching**: Case-insensitive keyword comparison
- **Partial Matching**: Handles variations (e.g., "JavaScript" matches "JS")
- **Weighted Scoring**: Important keywords (high TF-IDF) contribute more

**4. Match Score Calculation**

```
Match Score = (Matched Keywords / Total Job Keywords) √ó 100
```

Weighted by importance:
- Important keywords (high TF-IDF) contribute more
- Exact matches score higher than partial matches
- Bonus for matching high-importance skills

**5. Missing Skills Identification**

- Compare job description keywords against resume keywords
- Identify skills required by job but not found in resume
- Rank by importance (TF-IDF score from job description)

**6. Explanation Generation**

Human-readable explanation includes:
- Overall match score
- List of matched skills with match types
- List of missing skills
- Actionable recommendations based on score

### Why This Approach is Explainable

1. **Transparent Algorithms**: TF-IDF is a well-documented statistical method
2. **Traceable Logic**: Every match can be traced to specific keywords
3. **No Hidden Weights**: No neural network weights to interpret
4. **Auditable**: All calculations can be verified manually
5. **Interview-Ready**: Can explain the entire process step-by-step

### Database Design

**Core Tables:**
- **Users**: Authentication and user management
- **Resumes**: Uploaded PDF files and extracted text
- **Job Descriptions**: Job title and description text
- **Analysis Results**: Match scores, explanations, matched/missing keywords (JSON)

**Features:**
- UUID primary keys for distributed systems
- Timestamps for audit trails
- Foreign key relationships for data integrity
- Indexes on frequently queried fields
- Connection pooling for performance

---

## üì° API Documentation

### Authentication Endpoints

```
POST /api/v1/auth/register
  - Create new user account
  - Returns: User information

POST /api/v1/auth/login
  - Authenticate user
  - Returns: JWT access token
```

### Resume Endpoints

```
POST /api/v1/resume/upload
  - Upload PDF resume
  - Extracts text automatically
  - Returns: Resume metadata

GET /api/v1/resumes
  - Get all resumes for authenticated user
  - Returns: List of resumes
```

### Job Description Endpoints

```
POST /api/v1/job-description/create
  - Create job description
  - Returns: Job description ID

GET /api/v1/job-descriptions
  - Get all job descriptions for authenticated user
  - Returns: List of job descriptions
```

### Analysis Endpoints

```
POST /api/v1/analysis/run
  - Run resume vs job description analysis
  - Returns: Match score, matched skills, missing skills, explanation

GET /api/v1/analysis/{id}
  - Retrieve analysis result by ID
  - Returns: Complete analysis result
```

### Dashboard Endpoints

```
GET /api/v1/dashboard/summary
  - Get analysis statistics
  - Returns: Total analyses, average score, highest/lowest scores

GET /api/v1/dashboard/history
  - Get analysis history
  - Returns: List of past analyses with scores
```

### API Security

- JWT tokens expire after 30 minutes
- Password hashing with bcrypt (salt included)
- Protected endpoints require valid JWT
- User can only access their own data

---

## üìÅ Project Structure

### Backend Structure

```
backend/
‚îú‚îÄ‚îÄ app/
‚îÇ   ‚îú‚îÄ‚îÄ api/
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ v1/
‚îÇ   ‚îÇ       ‚îú‚îÄ‚îÄ endpoints/      # API route handlers
‚îÇ   ‚îÇ       ‚îî‚îÄ‚îÄ schemas/        # Pydantic models
‚îÇ   ‚îú‚îÄ‚îÄ core/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ config/             # Configuration management
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ dependencies.py    # FastAPI dependencies
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ security/          # Authentication & hashing
‚îÇ   ‚îú‚îÄ‚îÄ infrastructure/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ ai/                # Matching engine
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ database/          # Models, migrations, repositories
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ storage/           # File storage utilities
‚îÇ   ‚îî‚îÄ‚îÄ main.py               # FastAPI application entry
‚îú‚îÄ‚îÄ alembic.ini                # Alembic configuration
‚îú‚îÄ‚îÄ requirements.txt           # Python dependencies
‚îî‚îÄ‚îÄ pytest.ini                 # Test configuration
```

### Frontend Structure

```
frontend/
‚îú‚îÄ‚îÄ src/
‚îÇ   ‚îú‚îÄ‚îÄ components/           # Reusable UI components
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ common/          # Shared components
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ analysis/        # Analysis-specific components
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ job/             # Job description components
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ resume/          # Resume upload components
‚îÇ   ‚îú‚îÄ‚îÄ context/             # React Context providers
‚îÇ   ‚îú‚îÄ‚îÄ hooks/               # Custom React hooks
‚îÇ   ‚îú‚îÄ‚îÄ pages/               # Route pages
‚îÇ   ‚îú‚îÄ‚îÄ services/            # API service layer
‚îÇ   ‚îú‚îÄ‚îÄ types/               # TypeScript type definitions
‚îÇ   ‚îî‚îÄ‚îÄ utils/               # Utility functions
‚îú‚îÄ‚îÄ package.json
‚îî‚îÄ‚îÄ vite.config.ts
```

---

## üß™ Testing

### Testing Strategy

**Unit Tests:**
- Test individual functions in isolation
- Mock external dependencies
- Fast execution (milliseconds)
- Examples: Password hashing, JWT creation, matching algorithms

**Integration Tests:**
- Test API endpoints end-to-end
- Use test database (SQLite in-memory)
- Test component interactions
- Examples: Login flow, resume upload, analysis execution

**Test Coverage:**
- Critical paths: 90%+ (authentication, matching engine)
- API endpoints: 80%+ (all success and error cases)
- Business logic: 85%+ (keyword extraction, scoring)

### Running Tests

```bash
# Backend tests
cd backend
pytest

# With coverage
pytest --cov=app --cov-report=html

# Specific test file
pytest tests/unit/test_matching_engine.py

# Frontend tests
cd frontend
npm test
```

---

## üöÄ Future Enhancements

### Enhanced Matching

- **Semantic Similarity**: Word embeddings (Word2Vec, GloVe) for skill similarity
- **Synonym Detection**: Skill dictionary (e.g., "JS" = "JavaScript")
- **Context-Aware Matching**: Weight keywords by resume section (Experience > Education)

### Additional Features

- **Resume Version Comparison**: Track resume changes over time
- **Job Application Tracking**: Track applications and correlate with match scores
- **Advanced Analytics**: Industry-specific insights, skill demand trends

### Deployment Enhancements

- **Production Readiness**: Docker containerization, CI/CD pipeline
- **Performance**: Redis caching, background job queue (Celery), CDN
- **Monitoring**: Health checks, metrics, logging (Sentry, DataDog)

---

## üíº For Recruiters & Interviewers

### Elevator Pitch (30 seconds)

"I built a full-stack web application that analyzes resumes against job descriptions using explainable AI. Unlike black-box ATS systems, it provides transparent match scores and identifies missing skills, helping job seekers understand their fit and improve their applications."

### Technical Summary (2 minutes)

"The system uses FastAPI for the backend, React with TypeScript for the frontend, and PostgreSQL for data storage. The matching engine uses TF-IDF (Term Frequency-Inverse Document Frequency) to extract important keywords from both documents, then performs rule-based matching. This approach is fully explainable‚Äîevery match score can be traced back to specific skills. I implemented JWT authentication, file upload handling, and a responsive dashboard with analytics."

### Key Technical Talking Points

**1. Explainable AI Approach**
- Chose TF-IDF over neural networks for transparency
- Every match score can be traced to specific keywords
- Matching logic uses statistical methods, not black-box models

**2. Full-Stack Architecture**
- Separated concerns: API layer, business logic, data access
- Used dependency injection in FastAPI for testability
- Context API for global state, custom hooks for API calls

**3. Security Implementation**
- JWT tokens with expiration for stateless authentication
- Bcrypt password hashing with automatic salt generation
- User data isolation‚Äîusers can only access their own data

**4. Testing Strategy**
- Unit tests for business logic (matching engine, password hashing)
- Integration tests for API endpoints
- Test coverage: 90%+ for critical paths

**5. Scalability Considerations**
- Stateless API design enables horizontal scaling
- Database connection pooling for performance
- Async request handling with FastAPI

**6. User Experience**
- Implemented skeleton loaders and optimistic UI updates
- Accessible design with keyboard navigation and screen reader support
- Responsive layout with mobile-first approach

### Common Interview Questions

**Q: Why did you choose this approach over machine learning?**  
A: "I prioritized explainability over raw accuracy. In a job application context, users need to understand why they got a certain score. TF-IDF and rule-based matching provide transparency that neural networks don't. This approach is also easier to debug and maintain."

**Q: How would you improve the matching accuracy?**  
A: "I'd add semantic similarity using word embeddings (Word2Vec/GloVe) for skill matching. This would catch cases like 'ML' matching 'Machine Learning'. I'd also implement a skill dictionary for synonym detection. These improvements remain explainable‚Äîwe can show which embeddings matched."

**Q: How does this scale to thousands of users?**  
A: "The stateless API design allows horizontal scaling behind a load balancer. I'd add Redis caching for frequently accessed data, implement database read replicas for analytics, and use a background job queue (Celery) for long-running analysis tasks. The matching engine is CPU-bound but fast enough for real-time processing."

**Q: What was the most challenging part?**  
A: "Balancing explainability with accuracy. I had to design a matching algorithm that's both transparent and useful. The TF-IDF approach works well, but handling edge cases like skill variations required careful normalization logic."

---

## üìÑ License

This project is for portfolio and educational purposes.

---

## üìß Contact

For questions or feedback, please open an issue on GitHub.

---

<div align="center">

**Built with ‚ù§Ô∏è using FastAPI, React, and PostgreSQL**

[Back to Top](#-ai-resume-intelligence--career-copilot)

</div>
